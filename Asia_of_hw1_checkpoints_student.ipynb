{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asia281/dnn2022/blob/main/Asia_of_hw1_checkpoints_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpointing\n",
        "\n",
        "Your task is to implement checkpointing for a MLP using NumPy.\n",
        "\n",
        "You are free to use the implementation of a MLP and the backpropagation algorithm that you have developed during lab sessions.\n",
        "\n",
        "The key takeaway from this task is that with checkpointing we can trade off the computational resources needed to compute the forward pass of the network for the memory requirement needed to perform a backward pass in the network, which is often a major bottleneck when training large networks. In plain english, we can slightly increase the time required for training our network to save some of our GPU's precious memory.\n",
        "\n",
        "## What is checkpointing?\n",
        "\n",
        "The aim of checkpointing is to save every $n$-th layer's (e.g. every 2-nd layer's) forward result (instead of saving every layer's forward result as in plain backpropagation) and use these checkpoints for recomputing the forward pass of the network upon doing a backward pass. Checkpoint layers are kept in memory after the forward pass, while the remaining activations are recomputed at most once. After being recomputed, the non-checkpoint layers are kept in memory until they are no longer required."
      ],
      "metadata": {
        "collapsed": false,
        "id": "GvE1EOcmTjb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What should be done\n",
        "\n",
        "1. Take the implementation a MLP trained with backpropagation. Analyze the algorithm with respect to the memory that is used by the algorithm with respect to the number of hidden layers.\n",
        "\n",
        "2. Implement a class NetworkWithCheckpointing that inherits from the Network class defined during lab sessions by:\n",
        "    a) implementing a method `forward_between_checkpoints` that will recompute the forward pass of the network using one of the checkpointed layers\n",
        "    b) override the method `backprop` to use only checkpointed layers and otherwise compute the activations using `forward_between_checkpoints` method and keep it in memory until no longer needed.\n",
        "\n",
        "3. Train your network with checkpoinintg on MNIST. Compare running times and memory usage with respect to the network without checkpointing.\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "v0TLdcCnTjcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement Checkpointing for a MLP"
      ],
      "metadata": {
        "collapsed": false,
        "id": "aTR2VeRiTjcD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "hnE0ZkxnTjcD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-19 17:08:24--  https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.204.56, 52.217.201.104, 52.217.198.184, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.204.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11490434 (11M) [application/octet-stream]\n",
            "Saving to: ‘mnist.npz’\n",
            "\n",
            "mnist.npz           100%[===================>]  10.96M  5.97MB/s    in 1.8s    \n",
            "\n",
            "2022-11-19 17:08:27 (5.97 MB/s) - ‘mnist.npz’ saved [11490434/11490434]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O mnist.npz https://s3.amazonaws.com/img-datasets/mnist.npz"
      ],
      "metadata": {
        "id": "YS4zX3dFTjcF",
        "outputId": "21246cf8-f3a6-45c9-acd0-3d476a177d0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "source": [
        "# Let's read the mnist dataset\n",
        "\n",
        "def load_mnist(path='mnist.npz'):\n",
        "    with np.load(path) as f:\n",
        "        x_train, _y_train = f['x_train'], f['y_train']\n",
        "        x_test, _y_test = f['x_test'], f['y_test']\n",
        "\n",
        "    x_train = x_train.reshape(-1, 28 * 28) / 255.\n",
        "    x_test = x_test.reshape(-1, 28 * 28) / 255.\n",
        "\n",
        "    y_train = np.zeros((_y_train.shape[0], 10))\n",
        "    y_train[np.arange(_y_train.shape[0]), _y_train] = 1\n",
        "\n",
        "    y_test = np.zeros((_y_test.shape[0], 10))\n",
        "    y_test[np.arange(_y_test.shape[0]), _y_test] = 1\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = load_mnist()"
      ],
      "metadata": {
        "id": "D1-987dCTjcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "    # Derivative of the sigmoid\n",
        "    return sigmoid(z)*(1-sigmoid(z))\n",
        "\n",
        "def softmax(z):\n",
        "    # Numericaly stable\n",
        "    exps = np.exp(z - np.max(z))\n",
        "    sum = np.sum(exps, axis=0)\n",
        "    res = exps / sum\n",
        "    return res"
      ],
      "metadata": {
        "id": "CEWEdu5XVkEm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "source": [
        "class Network(object):\n",
        "    def __init__(self, sizes, l2=0.0, momentum=0.0):\n",
        "        # initialize biases and weights with random normal distr.\n",
        "        # weights are indexed by target node first\n",
        "        self.num_layers = len(sizes)\n",
        "        self.sizes = sizes\n",
        "        self.l2 = l2\n",
        "        self.momentum = momentum\n",
        "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
        "        self.weights = [np.random.randn(y, x)\n",
        "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
        "        self.weights_momentum = [np.zeros_like(x) for x in self.weights]\n",
        "        self.biases_momentum = [np.zeros_like(x) for x in self.biases]\n",
        "    \n",
        "    def activation(self, z, l):\n",
        "        if l == (self.num_layers - 1):\n",
        "            return softmax(z)\n",
        "\n",
        "        return sigmoid(z)\n",
        "    \n",
        "    def feedforward(self, a):\n",
        "        # Run the network on a batch\n",
        "        a = a.T\n",
        "        for l, b, w in zip(range(1, self.num_layers), self.biases, self.weights):\n",
        "          a = self.activation(np.matmul(w, a)+b, l)\n",
        "        return a\n",
        "    \n",
        "    def update_mini_batch(self, mini_batch, eta):\n",
        "        # Update networks weights and biases by applying a single step\n",
        "        # of gradient descent using backpropagation to compute the gradient.\n",
        "        # The gradient is computed for a mini_batch which is as in tensorflow API.\n",
        "        # eta is the learning rate      \n",
        "        nabla_b, nabla_w = self.backprop(mini_batch[0].T,mini_batch[1].T)\n",
        "        \n",
        "        ### Momentum equation for parameter p\n",
        "        ### p_(t+1) = p_t + m_(t+1)\n",
        "        ### m_(t+1) = lambda_momentum * m_t - eta * gradient(p_t)\n",
        "        self.weights_momentum = [(self.momentum*wm)-(eta/len(mini_batch[0]))*nw \n",
        "                                 for wm, w, nw in zip(self.weights_momentum, self.weights, nabla_w)]\n",
        "        self.biases_momentum = [(self.momentum*bm)-(eta/len(mini_batch[0]))*nb \n",
        "                                for bm, b, nb in zip(self.biases_momentum, self.biases, nabla_b)]\n",
        "                            \n",
        "        self.weights = [w+wm for w, wm in zip(self.weights, self.weights_momentum)]\n",
        "        self.biases = [b+bm for b, bm in zip(self.biases, self.biases_momentum)]\n",
        "        \n",
        "    def backprop(self, x, y):\n",
        "        g = x\n",
        "        gs = [g] # list to store all the gs, layer by layer\n",
        "        fs = [] # list to store all the fs, layer by layer\n",
        "        for l, b, w in zip(range(1, self.num_layers), self.biases, self.weights):\n",
        "            f = np.dot(w, g)+b\n",
        "            fs.append(f)\n",
        "            g = self.activation(f, l)\n",
        "            gs.append(g)\n",
        "            \n",
        "        dLdf = self.cost_derivative(gs[-1], y)\n",
        "        dLdfs = []\n",
        "        for l,w,g in reversed(list(zip(range(1, self.num_layers), self.weights, gs[1:]))):\n",
        "            if l < (self.num_layers - 1):\n",
        "                dLdf = np.multiply(dLdg, np.multiply(g,1-g))\n",
        "            dLdfs.append(dLdf)\n",
        "            dLdg = np.matmul(w.T, dLdf)\n",
        "        \n",
        "        dLdWs = [np.matmul(dLdf,g.T) for dLdf,g in zip(reversed(dLdfs),gs[:-1])] \n",
        "        dLdBs = [np.sum(dLdf,axis=1).reshape(dLdf.shape[0],1) for dLdf in reversed(dLdfs)] \n",
        "\n",
        "        dLdWs = [dLdW + (self.l2 * w) for dLdW, w in zip(dLdWs, self.weights)]\n",
        "\n",
        "        return (dLdBs, dLdWs)\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        # Count the number of correct answers for test_data\n",
        "        pred = np.argmax(self.feedforward(test_data[0]),axis=0)\n",
        "        corr = np.argmax(test_data[1],axis=1).T\n",
        "        return np.mean(pred==corr)\n",
        "    \n",
        "    def cost_derivative(self, output_activations, y):\n",
        "        return (output_activations-y) \n",
        "    \n",
        "    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n",
        "        x_train, y_train = training_data\n",
        "        if test_data:\n",
        "            x_test, y_test = test_data\n",
        "        for j in range(epochs):\n",
        "            for i in range(x_train.shape[0] // mini_batch_size):\n",
        "                x_mini_batch = x_train[(mini_batch_size*i):(mini_batch_size*(i+1))]\n",
        "                y_mini_batch = y_train[(mini_batch_size*i):(mini_batch_size*(i+1))]\n",
        "                self.update_mini_batch((x_mini_batch, y_mini_batch), eta)\n",
        "            if test_data:\n",
        "                print(\"Epoch: {0}, Accuracy: {1}\".format(j, self.evaluate((x_test, y_test))))\n",
        "            else:\n",
        "                print(\"Epoch: {0}\".format(j))"
      ],
      "metadata": {
        "id": "kEvKH9BRTjcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = Network([784,30,10], l2=0.001, momentum=0.7)\n",
        "%time network.SGD((x_train, y_train), epochs=20, mini_batch_size=100, eta=3., test_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb1nhwHjX0F2",
        "outputId": "ca22fcb8-ed71-44f7-97f6-b955111bf560"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Accuracy: 0.9063\n",
            "Epoch: 1, Accuracy: 0.9186\n",
            "Epoch: 2, Accuracy: 0.9283\n",
            "Epoch: 3, Accuracy: 0.9321\n",
            "Epoch: 4, Accuracy: 0.9351\n",
            "Epoch: 5, Accuracy: 0.9447\n",
            "Epoch: 6, Accuracy: 0.9473\n",
            "Epoch: 7, Accuracy: 0.9397\n",
            "Epoch: 8, Accuracy: 0.9421\n",
            "Epoch: 9, Accuracy: 0.9441\n",
            "Epoch: 10, Accuracy: 0.9393\n",
            "Epoch: 11, Accuracy: 0.9452\n",
            "Epoch: 12, Accuracy: 0.9396\n",
            "Epoch: 13, Accuracy: 0.9431\n",
            "Epoch: 14, Accuracy: 0.9388\n",
            "Epoch: 15, Accuracy: 0.9499\n",
            "Epoch: 16, Accuracy: 0.9451\n",
            "Epoch: 17, Accuracy: 0.9506\n",
            "Epoch: 18, Accuracy: 0.9492\n",
            "Epoch: 19, Accuracy: 0.946\n",
            "CPU times: user 33.3 s, sys: 14.2 s, total: 47.5 s\n",
            "Wall time: 27.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [],
      "source": [
        "class NetworkWithCheckpointing(Network):\n",
        "    def __init__(self, sizes, checkpoint_every_nth_layer: int = 0, *args, **kwargs):\n",
        "        super().__init__(sizes, *args, **kwargs)\n",
        "        self.checkpoint_freq = checkpoint_every_nth_layer\n",
        "        self.layers_nr = len(sizes)\n",
        "\n",
        "    def get(self, d: dict, idx: int):\n",
        "      if idx in d:\n",
        "        return d[idx]\n",
        "      d[idx] = sigmoid(np.matmul(self.weights[idx - 1], self.get(d, idx - 1)) + self.biases[idx - 1])\n",
        "      return d[idx]\n",
        "\n",
        "    def delete(self, d: dict, idx: int):\n",
        "      if idx % self.checkpoint_freq != 0 and idx in d:\n",
        "        del d[idx]\n",
        "\n",
        "    def forward_between_checkpoints(self, a, start, end):\n",
        "      is_last = (end == self.layers_nr - 1)\n",
        "      if is_last:\n",
        "        end -= 1\n",
        "      for b, w in zip(self.biases[start:end], self.weights[start:end]):\n",
        "        a = sigmoid(np.dot(w, a) + b)   \n",
        "      if is_last:\n",
        "        return softmax(np.matmul(self.weights[-1], a) + self.biases[-1])\n",
        "\n",
        "      return a\n",
        "\n",
        "    def backprop(self, x, y):\n",
        "      gs = {}\n",
        "      g = x\n",
        "      gs[0] = g\n",
        "\n",
        "      for i in range(0, self.layers_nr - 1, self.checkpoint_freq):\n",
        "        end = min(self.layers_nr - 1, i + self.checkpoint_freq)\n",
        "        g = self.forward_between_checkpoints(g, i, end)\n",
        "        gs[end] = g\n",
        "      # backward pass <- both steps at once\n",
        "      idx = self.layers_nr - 1\n",
        "      dLdf = self.cost_derivative(gs[idx], y)\n",
        "      dLdfs = []\n",
        "      dLdWs = []\n",
        "      for idx, w in reversed(list(zip(range(1, self.num_layers), self.weights))):\n",
        "        if idx < (self.num_layers - 1):\n",
        "          g = self.get(gs, idx)\n",
        "          self.delete(gs, idx)\n",
        "          dLdf = np.multiply(dLdg,np.multiply(g,1-g))\n",
        "\n",
        "        dLdfs.append(dLdf)\n",
        "        dLdg = np.matmul(w.T, dLdf)\n",
        "\n",
        "      for idx, w in enumerate(reversed(dLdfs)):\n",
        "        dLdWs.append(np.matmul(w, self.get(gs, idx).T))\n",
        "        if idx > 0:\n",
        "          self.delete(gs, idx-1)\n",
        "      \n",
        "      dLdWs = [dLdW + (self.l2 * w) for dLdW, w in zip(dLdWs, self.weights)]\n",
        "      dLdBs = [np.sum(dLdf,axis=1).reshape(dLdf.shape[0],1) for dLdf in reversed(dLdfs)] \n",
        "      return (dLdBs, dLdWs)\n",
        "\n",
        "        \n"
      ],
      "metadata": {
        "id": "Xc1MHTzpTjcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net_check = NetworkWithCheckpointing([784,30,10], 2)\n",
        "%time net_check.SGD((x_train, y_train), epochs=20, mini_batch_size=100, eta=3., test_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "PTmQ8WcZh_gW",
        "outputId": "a694494a-eeec-4607-de96-c31b8b89feb0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Accuracy: 0.8923\n",
            "Epoch: 1, Accuracy: 0.9132\n",
            "Epoch: 2, Accuracy: 0.9227\n",
            "Epoch: 3, Accuracy: 0.9272\n",
            "Epoch: 4, Accuracy: 0.9341\n",
            "Epoch: 5, Accuracy: 0.9347\n",
            "Epoch: 6, Accuracy: 0.9362\n",
            "Epoch: 7, Accuracy: 0.9398\n",
            "Epoch: 8, Accuracy: 0.9418\n",
            "Epoch: 9, Accuracy: 0.9419\n",
            "Epoch: 10, Accuracy: 0.9429\n",
            "Epoch: 11, Accuracy: 0.9425\n",
            "Epoch: 12, Accuracy: 0.944\n",
            "Epoch: 13, Accuracy: 0.9449\n",
            "Epoch: 14, Accuracy: 0.9452\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d890514b225d>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, test_data)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mx_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0my_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {0}, Accuracy: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d890514b225d>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[0;34m(self, mini_batch, eta)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# The gradient is computed for a mini_batch which is as in tensorflow API.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# eta is the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mnabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m### Momentum equation for parameter p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-c57a6186bedb>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdLdWs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network = Network([784,30,30,10], l2=0.001, momentum=0.6)\n",
        "%time network.SGD((x_train, y_train), epochs=20, mini_batch_size=100, eta=3., test_data=(x_test, y_test))\n",
        "\n",
        "network_check = NetworkWithCheckpointing([784,30,30,10], 2, l2=0.001, momentum=0.6)\n",
        "%time network_check.SGD((x_train, y_train), epochs=20, mini_batch_size=100, eta=3., test_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "RBUG0O8igfqY",
        "outputId": "05f3b72b-39d7-400a-abfd-0bdb619a7fa4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Accuracy: 0.8771\n",
            "Epoch: 1, Accuracy: 0.9167\n",
            "Epoch: 2, Accuracy: 0.9125\n",
            "Epoch: 3, Accuracy: 0.928\n",
            "Epoch: 4, Accuracy: 0.9285\n",
            "Epoch: 5, Accuracy: 0.9352\n",
            "Epoch: 6, Accuracy: 0.9345\n",
            "Epoch: 7, Accuracy: 0.9361\n",
            "Epoch: 8, Accuracy: 0.9377\n",
            "Epoch: 9, Accuracy: 0.9408\n",
            "Epoch: 10, Accuracy: 0.9339\n",
            "Epoch: 11, Accuracy: 0.9371\n",
            "Epoch: 12, Accuracy: 0.9423\n",
            "Epoch: 13, Accuracy: 0.9421\n",
            "Epoch: 14, Accuracy: 0.942\n",
            "Epoch: 15, Accuracy: 0.939\n",
            "Epoch: 16, Accuracy: 0.9396\n",
            "Epoch: 17, Accuracy: 0.9423\n",
            "Epoch: 18, Accuracy: 0.9423\n",
            "Epoch: 19, Accuracy: 0.9456\n",
            "CPU times: user 37.6 s, sys: 14.7 s, total: 52.3 s\n",
            "Wall time: 27.7 s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d890514b225d>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, eta, test_data)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mx_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0my_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {0}, Accuracy: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-d890514b225d>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[0;34m(self, mini_batch, eta)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# The gradient is computed for a mini_batch which is as in tensorflow API.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# eta is the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mnabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m### Momentum equation for parameter p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-21cd2b83c054>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0mdLdWs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdLdW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdLdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdWs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mdLdW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mdLdWs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdLdW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LH7fyxk63Sjf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}