{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asia281/dnn2022/blob/main/Asia_of_DNN_Lab_5_Batchrnorm_and_Convnets_student_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n",
        "\n",
        "AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Program Operacyjny Polska Cyfrowa na lata 2014-2020\n",
        "<hr>\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n",
        "\n",
        "<center>\n",
        "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego \n",
        "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
        "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\" \n",
        "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
        "    </center>"
      ],
      "metadata": {
        "id": "BfdcY0Vq6e80"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcTwzhX8fBqs"
      },
      "source": [
        "Code based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "\n",
        "This exercise covers two aspects:\n",
        "* In tasks 1-6 you will implement mechanisms that allow training deeper models (better initialization, batch normalization). Note that for dropout and batch norm you are expected to implement it yourself without relying on ready-made components from Pytorch.\n",
        "* In task 7 you will implement a convnet using [conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html).\n",
        "\n",
        "\n",
        "Tasks:\n",
        "1. Check that the given implementation reaches 95% test accuracy for\n",
        "   architecture input-64-64-10 in a few thousand batches.\n",
        "2. Improve initialization and check that the network learns much faster\n",
        "   and reaches over 97% test accuracy. A good basic initialization scheme is so-called Glorot initialization. For a set of weights going from a layer with $n_{in}$ neurons to a layer with $n_{out}$ neurons, it samples each weight from normal distribution with $0$ mean and standard deviation of $\\sqrt{\\frac{2}{n_{in}+n_{out}}}$.\n",
        "3. Check, that with proper initialization we can train architecture\n",
        "   input-64-64-64-64-64-10, while with bad initialization it does\n",
        "   not even get off the ground.\n",
        "4. Add dropout implemented in pytorch\n",
        "5. Check that with 10 hidden layers (64 units each) even with proper\n",
        "    initialization the network has a hard time to start learning.\n",
        "6. Implement batch normalization (use train mode also for testing - it should perform well enough):\n",
        "    * compute batch mean and variance\n",
        "    * add new variables beta and gamma\n",
        "    * check that the networks learns much faster for 5 layers\n",
        "    * check that the network learns even for 10 hidden layers.\n",
        "7. So far we worked with a fully connected network. Design and implement in pytorch (by using pytorch functions) a simple convolutional network and achieve 99% test accuracy. The architecture is up to you, but even a few convolutional layers should be enough."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stride = krok and pull "
      ],
      "metadata": {
        "id": "KuPwZ05lTY8g"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYAsziKffBFV"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMtap4QCfBH8"
      },
      "source": [
        "class Linear(torch.nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(Linear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.bias = Parameter(torch.Tensor(out_features))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.weight.data.normal_(mean=0,std=0.25)\n",
        "        init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r = x.matmul(self.weight.t())\n",
        "        r += self.bias\n",
        "        return r\n",
        "\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, sizes: List, linear = Linear):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.ModuleList([linear(in_features=in_f, out_features=out_f) for in_f, out_f in zip(sizes, sizes[1:])])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        for layer in self.fc[:-1]:\n",
        "          x = F.relu(layer(x))\n",
        "        x = self.fc[-1](x)\n",
        "        return x\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a set of weights going from a layer with $n_{in}$ neurons to a layer with $n_{out}$ neurons, it samples each weight from normal distribution with $0$ mean and standard deviation of $\\sqrt{\\frac{2}{n_{in}+n_{out}}}$."
      ],
      "metadata": {
        "id": "NLJmKbPvSAKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.nn.init.xavier_uniform(self.weight)\n",
        "import math\n",
        "\n",
        "class LinearGlorot(Linear):\n",
        "    def __init__(self, **kwargs):\n",
        "      super().__init__(**kwargs)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        init.xavier_normal_(self.weight)\n",
        "        init.zeros_(self.bias)\n"
      ],
      "metadata": {
        "id": "H3DUxcNzRhEt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgfUP23AfBMd"
      },
      "source": [
        "class MnistTrainer(object):\n",
        "    def __init__(self, batch_size):\n",
        "        transform = transforms.Compose(\n",
        "                [transforms.ToTensor()])\n",
        "        self.trainset = torchvision.datasets.MNIST(\n",
        "            root='./data',\n",
        "            download=True,\n",
        "            train=True,\n",
        "            transform=transform)\n",
        "        self.trainloader = torch.utils.data.DataLoader(\n",
        "            self.trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "        self.testset = torchvision.datasets.MNIST(\n",
        "            root='./data',\n",
        "            train=False,\n",
        "            download=True, transform=transform)\n",
        "        self.testloader = torch.utils.data.DataLoader(\n",
        "            self.testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "    def train(self, net = Net([784, 64, 64, 10])):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.9)\n",
        "\n",
        "        for epoch in range(20):\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(self.trainloader, 0):\n",
        "                inputs, labels = data\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                if i % 100 == 99:\n",
        "                    print('[%d, %5d] loss: %.3f' %\n",
        "                          (epoch + 1, i + 1, running_loss / 100))\n",
        "                    running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for data in self.testloader:\n",
        "                    images, labels = data\n",
        "                    outputs = net(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "            print('Accuracy of the network on the {} test images: {} %'.format(\n",
        "                total, 100 * correct / total))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezvIQbgsfBRT",
        "outputId": "b9145742-7997-46e4-9597-72a1c705d046"
      },
      "source": [
        "trainer = MnistTrainer(batch_size=128)\n",
        "trainer.train()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 0.809\n",
            "[1,   200] loss: 0.336\n",
            "[1,   300] loss: 0.277\n",
            "[1,   400] loss: 0.246\n",
            "Accuracy of the network on the 10000 test images: 93.8 %\n",
            "[2,   100] loss: 0.182\n",
            "[2,   200] loss: 0.185\n",
            "[2,   300] loss: 0.175\n",
            "[2,   400] loss: 0.164\n",
            "Accuracy of the network on the 10000 test images: 94.94 %\n",
            "[3,   100] loss: 0.138\n",
            "[3,   200] loss: 0.148\n",
            "[3,   300] loss: 0.130\n",
            "[3,   400] loss: 0.130\n",
            "Accuracy of the network on the 10000 test images: 95.76 %\n",
            "[4,   100] loss: 0.108\n",
            "[4,   200] loss: 0.115\n",
            "[4,   300] loss: 0.109\n",
            "[4,   400] loss: 0.118\n",
            "Accuracy of the network on the 10000 test images: 95.69 %\n",
            "[5,   100] loss: 0.089\n",
            "[5,   200] loss: 0.092\n",
            "[5,   300] loss: 0.098\n",
            "[5,   400] loss: 0.107\n",
            "Accuracy of the network on the 10000 test images: 96.05 %\n",
            "[6,   100] loss: 0.076\n",
            "[6,   200] loss: 0.082\n",
            "[6,   300] loss: 0.085\n",
            "[6,   400] loss: 0.086\n",
            "Accuracy of the network on the 10000 test images: 96.25 %\n",
            "[7,   100] loss: 0.074\n",
            "[7,   200] loss: 0.076\n",
            "[7,   300] loss: 0.067\n",
            "[7,   400] loss: 0.075\n",
            "Accuracy of the network on the 10000 test images: 96.57 %\n",
            "[8,   100] loss: 0.066\n",
            "[8,   200] loss: 0.060\n",
            "[8,   300] loss: 0.066\n",
            "[8,   400] loss: 0.073\n",
            "Accuracy of the network on the 10000 test images: 96.76 %\n",
            "[9,   100] loss: 0.053\n",
            "[9,   200] loss: 0.061\n",
            "[9,   300] loss: 0.058\n",
            "[9,   400] loss: 0.061\n",
            "Accuracy of the network on the 10000 test images: 96.49 %\n",
            "[10,   100] loss: 0.047\n",
            "[10,   200] loss: 0.052\n",
            "[10,   300] loss: 0.056\n",
            "[10,   400] loss: 0.051\n",
            "Accuracy of the network on the 10000 test images: 97.11 %\n",
            "[11,   100] loss: 0.043\n",
            "[11,   200] loss: 0.044\n",
            "[11,   300] loss: 0.048\n",
            "[11,   400] loss: 0.045\n",
            "Accuracy of the network on the 10000 test images: 96.9 %\n",
            "[12,   100] loss: 0.035\n",
            "[12,   200] loss: 0.043\n",
            "[12,   300] loss: 0.038\n",
            "[12,   400] loss: 0.042\n",
            "Accuracy of the network on the 10000 test images: 96.58 %\n",
            "[13,   100] loss: 0.031\n",
            "[13,   200] loss: 0.032\n",
            "[13,   300] loss: 0.034\n",
            "[13,   400] loss: 0.043\n",
            "Accuracy of the network on the 10000 test images: 96.92 %\n",
            "[14,   100] loss: 0.030\n",
            "[14,   200] loss: 0.031\n",
            "[14,   300] loss: 0.035\n",
            "[14,   400] loss: 0.037\n",
            "Accuracy of the network on the 10000 test images: 96.88 %\n",
            "[15,   100] loss: 0.032\n",
            "[15,   200] loss: 0.025\n",
            "[15,   300] loss: 0.030\n",
            "[15,   400] loss: 0.033\n",
            "Accuracy of the network on the 10000 test images: 97.01 %\n",
            "[16,   100] loss: 0.024\n",
            "[16,   200] loss: 0.021\n",
            "[16,   300] loss: 0.028\n",
            "[16,   400] loss: 0.028\n",
            "Accuracy of the network on the 10000 test images: 96.84 %\n",
            "[17,   100] loss: 0.018\n",
            "[17,   200] loss: 0.020\n",
            "[17,   300] loss: 0.031\n",
            "[17,   400] loss: 0.026\n",
            "Accuracy of the network on the 10000 test images: 97.17 %\n",
            "[18,   100] loss: 0.013\n",
            "[18,   200] loss: 0.019\n",
            "[18,   300] loss: 0.018\n",
            "[18,   400] loss: 0.021\n",
            "Accuracy of the network on the 10000 test images: 97.08 %\n",
            "[19,   100] loss: 0.014\n",
            "[19,   200] loss: 0.013\n",
            "[19,   300] loss: 0.018\n",
            "[19,   400] loss: 0.021\n",
            "Accuracy of the network on the 10000 test images: 97.03 %\n",
            "[20,   100] loss: 0.017\n",
            "[20,   200] loss: 0.014\n",
            "[20,   300] loss: 0.016\n",
            "[20,   400] loss: 0.018\n",
            "Accuracy of the network on the 10000 test images: 96.51 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQMSSwuifBTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900d38e6-aebc-45b1-c679-7d5ea4599729"
      },
      "source": [
        "trainer = MnistTrainer(batch_size=128)\n",
        "trainer.train(Net([784, 64, 64, 10], LinearGlorot))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 0.746\n",
            "[1,   200] loss: 0.287\n",
            "[1,   300] loss: 0.225\n",
            "[1,   400] loss: 0.186\n",
            "Accuracy of the network on the 10000 test images: 95.69 %\n",
            "[2,   100] loss: 0.160\n",
            "[2,   200] loss: 0.145\n",
            "[2,   300] loss: 0.125\n",
            "[2,   400] loss: 0.123\n",
            "Accuracy of the network on the 10000 test images: 96.3 %\n",
            "[3,   100] loss: 0.098\n",
            "[3,   200] loss: 0.103\n",
            "[3,   300] loss: 0.093\n",
            "[3,   400] loss: 0.109\n",
            "Accuracy of the network on the 10000 test images: 96.98 %\n",
            "[4,   100] loss: 0.076\n",
            "[4,   200] loss: 0.077\n",
            "[4,   300] loss: 0.077\n",
            "[4,   400] loss: 0.079\n",
            "Accuracy of the network on the 10000 test images: 96.69 %\n",
            "[5,   100] loss: 0.064\n",
            "[5,   200] loss: 0.064\n",
            "[5,   300] loss: 0.075\n",
            "[5,   400] loss: 0.071\n",
            "Accuracy of the network on the 10000 test images: 96.96 %\n",
            "[6,   100] loss: 0.049\n",
            "[6,   200] loss: 0.058\n",
            "[6,   300] loss: 0.062\n",
            "[6,   400] loss: 0.059\n",
            "Accuracy of the network on the 10000 test images: 97.25 %\n",
            "[7,   100] loss: 0.047\n",
            "[7,   200] loss: 0.050\n",
            "[7,   300] loss: 0.053\n",
            "[7,   400] loss: 0.056\n",
            "Accuracy of the network on the 10000 test images: 97.17 %\n",
            "[8,   100] loss: 0.035\n",
            "[8,   200] loss: 0.048\n",
            "[8,   300] loss: 0.045\n",
            "[8,   400] loss: 0.042\n",
            "Accuracy of the network on the 10000 test images: 97.49 %\n",
            "[9,   100] loss: 0.035\n",
            "[9,   200] loss: 0.034\n",
            "[9,   300] loss: 0.041\n",
            "[9,   400] loss: 0.043\n",
            "Accuracy of the network on the 10000 test images: 97.61 %\n",
            "[10,   100] loss: 0.026\n",
            "[10,   200] loss: 0.034\n",
            "[10,   300] loss: 0.037\n",
            "[10,   400] loss: 0.051\n",
            "Accuracy of the network on the 10000 test images: 97.58 %\n",
            "[11,   100] loss: 0.033\n",
            "[11,   200] loss: 0.031\n",
            "[11,   300] loss: 0.031\n",
            "[11,   400] loss: 0.029\n",
            "Accuracy of the network on the 10000 test images: 97.38 %\n",
            "[12,   100] loss: 0.027\n",
            "[12,   200] loss: 0.026\n",
            "[12,   300] loss: 0.035\n",
            "[12,   400] loss: 0.025\n",
            "Accuracy of the network on the 10000 test images: 97.47 %\n",
            "[13,   100] loss: 0.018\n",
            "[13,   200] loss: 0.018\n",
            "[13,   300] loss: 0.025\n",
            "[13,   400] loss: 0.023\n",
            "Accuracy of the network on the 10000 test images: 97.7 %\n",
            "[14,   100] loss: 0.016\n",
            "[14,   200] loss: 0.016\n",
            "[14,   300] loss: 0.023\n",
            "[14,   400] loss: 0.020\n",
            "Accuracy of the network on the 10000 test images: 97.71 %\n",
            "[15,   100] loss: 0.012\n",
            "[15,   200] loss: 0.012\n",
            "[15,   300] loss: 0.018\n",
            "[15,   400] loss: 0.016\n",
            "Accuracy of the network on the 10000 test images: 97.56 %\n",
            "[16,   100] loss: 0.017\n",
            "[16,   200] loss: 0.015\n",
            "[16,   300] loss: 0.014\n",
            "[16,   400] loss: 0.021\n",
            "Accuracy of the network on the 10000 test images: 97.62 %\n",
            "[17,   100] loss: 0.012\n",
            "[17,   200] loss: 0.014\n",
            "[17,   300] loss: 0.016\n",
            "[17,   400] loss: 0.013\n",
            "Accuracy of the network on the 10000 test images: 97.72 %\n",
            "[18,   100] loss: 0.011\n",
            "[18,   200] loss: 0.011\n",
            "[18,   300] loss: 0.015\n",
            "[18,   400] loss: 0.014\n",
            "Accuracy of the network on the 10000 test images: 97.8 %\n",
            "[19,   100] loss: 0.010\n",
            "[19,   200] loss: 0.010\n",
            "[19,   300] loss: 0.014\n",
            "[19,   400] loss: 0.012\n",
            "Accuracy of the network on the 10000 test images: 97.68 %\n",
            "[20,   100] loss: 0.012\n",
            "[20,   200] loss: 0.009\n",
            "[20,   300] loss: 0.012\n",
            "[20,   400] loss: 0.016\n",
            "Accuracy of the network on the 10000 test images: 97.65 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Check, that with proper initialization we can train architecture\n",
        "   input-64-64-64-64-64-10, while with bad initialization it does\n",
        "   not even get off the ground."
      ],
      "metadata": {
        "id": "tL7eFp7eTsRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = MnistTrainer(batch_size=128)\n",
        "trainer.train(Net([784, 64, 64, 64, 64, 64, 10]))"
      ],
      "metadata": {
        "id": "2ytuFcneTQXb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1149cf78-3c9f-41ef-934f-796b4e31afb9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "Traceback (most recent call last):\n",
            "      File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "self._shutdown_workers()\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "        if w.is_alive():if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: \n",
            "can only test a child processAssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 2.363\n",
            "[1,   200] loss: 0.791\n",
            "[1,   300] loss: 0.555\n",
            "[1,   400] loss: 0.441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 88.93 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in:   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>\n",
            "    Traceback (most recent call last):\n",
            "self._shutdown_workers()  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    if w.is_alive():  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    \n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError\n",
            ": AssertionError: can only test a child processcan only test a child process\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2,   100] loss: 0.360\n",
            "[2,   200] loss: 0.339\n",
            "[2,   300] loss: 0.317\n",
            "[2,   400] loss: 0.282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 91.61 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "Exception ignored in:     if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Traceback (most recent call last):\n",
            "\n",
            "AssertionError  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            ":     can only test a child process\n",
            "self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3,   100] loss: 0.260\n",
            "[3,   200] loss: 0.261\n",
            "[3,   300] loss: 0.238\n",
            "[3,   400] loss: 0.235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 93.11 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "        if w.is_alive():self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "\n",
            "      File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    if w.is_alive():AssertionError\n",
            ":   File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n",
            "\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4,   100] loss: 0.223\n",
            "[4,   200] loss: 0.201\n",
            "[4,   300] loss: 0.212\n",
            "[4,   400] loss: 0.206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff8d7836170>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1493, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-293284a0272b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMnistTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-54a0eb0d9ef2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, net)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mdeliver_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'md5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdigest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWELCOME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "4. Add dropout implemented in pytorch\n",
        "\n"
      ],
      "metadata": {
        "id": "ZGUkO6NcS2-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = MnistTrainer(batch_size=128)\n",
        "trainer.train(Net([784, 64, 64, 64, 64, 64, 10], LinearGlorot))"
      ],
      "metadata": {
        "id": "crrzAfN8TEkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Check that with 10 hidden layers (64 units each) even with proper\n",
        "    initialization the network has a hard time to start learning.\n"
      ],
      "metadata": {
        "id": "Hk1Q1tEITx82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = MnistTrainer(batch_size=128)\n",
        "trainer.train(Net([784, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 10]))"
      ],
      "metadata": {
        "id": "4wGHfXsqTxJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = MnistTrainer(batch_size=128)\n",
        "trainer.train(Net([784, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 10], LinearGlorot))"
      ],
      "metadata": {
        "id": "kD9GRuYxUDPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Implement batch normalization (use train mode also for testing - it should perform well enough):\n",
        "compute batch mean and variance\n",
        "add new variables beta and gamma\n",
        "check that the networks learns much faster for 5 layers\n",
        "check that the network learns even for 10 hidden layers."
      ],
      "metadata": {
        "id": "fN8pOzRJS8qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_normalization(x, gamma, beta, moving_mean, moving_var, eps=1e-5, momentum=0.9):\n",
        "    if not torch.is_grad_enabled():\n",
        "        x_norm = (x - moving_mean) / torch.sqrt(moving_var + eps)\n",
        "    else:\n",
        "        mean = x.mean(dim=0, keepdims=True)\n",
        "        var = ((x - mean) ** 2).mean(dim=0, keepdims=True)\n",
        "        x_norm = (x - mean) / torch.sqrt(var + eps)\n",
        "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
        "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
        "    x = gamma * x_norm + beta\n",
        "    return x, moving_mean.data, moving_var.data"
      ],
      "metadata": {
        "id": "SuTzcbFFUsYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "7. So far we worked with a fully connected network. Design and implement in pytorch (by using pytorch functions) a simple convolutional network and achieve 99% test accuracy. The architecture is up to you, but even a few convolutional layers should be enough."
      ],
      "metadata": {
        "id": "83Gpl5e2TvW6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX_2rCycfBWU"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 5, 1, 2)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5, 1, 2)\n",
        "        self.fc1 = nn.Linear(32 * 7 *7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = MnistTrainer(batch_size=128)\n",
        "trainer.train(ConvNet())"
      ],
      "metadata": {
        "id": "llSK2eFfOz9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0368888-8732-4d1f-c940-851c2e095abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 0.748\n",
            "[1,   200] loss: 0.137\n",
            "[1,   300] loss: 0.099\n",
            "[1,   400] loss: 0.082\n",
            "Accuracy of the network on the 10000 test images: 98.15 %\n",
            "[2,   100] loss: 0.062\n",
            "[2,   200] loss: 0.057\n",
            "[2,   300] loss: 0.056\n",
            "[2,   400] loss: 0.056\n",
            "Accuracy of the network on the 10000 test images: 98.59 %\n",
            "[3,   100] loss: 0.043\n",
            "[3,   200] loss: 0.042\n",
            "[3,   300] loss: 0.041\n",
            "[3,   400] loss: 0.048\n",
            "Accuracy of the network on the 10000 test images: 98.71 %\n",
            "[4,   100] loss: 0.036\n",
            "[4,   200] loss: 0.031\n",
            "[4,   300] loss: 0.033\n",
            "[4,   400] loss: 0.033\n",
            "Accuracy of the network on the 10000 test images: 98.87 %\n",
            "[5,   100] loss: 0.025\n",
            "[5,   200] loss: 0.029\n",
            "[5,   300] loss: 0.027\n",
            "[5,   400] loss: 0.034\n",
            "Accuracy of the network on the 10000 test images: 98.82 %\n",
            "[6,   100] loss: 0.020\n",
            "[6,   200] loss: 0.024\n",
            "[6,   300] loss: 0.024\n",
            "[6,   400] loss: 0.025\n",
            "Accuracy of the network on the 10000 test images: 98.92 %\n",
            "[7,   100] loss: 0.020\n",
            "[7,   200] loss: 0.021\n",
            "[7,   300] loss: 0.022\n",
            "[7,   400] loss: 0.023\n",
            "Accuracy of the network on the 10000 test images: 99.05 %\n",
            "[8,   100] loss: 0.016\n",
            "[8,   200] loss: 0.017\n",
            "[8,   300] loss: 0.021\n",
            "[8,   400] loss: 0.019\n",
            "Accuracy of the network on the 10000 test images: 99.18 %\n",
            "[9,   100] loss: 0.017\n",
            "[9,   200] loss: 0.017\n",
            "[9,   300] loss: 0.018\n",
            "[9,   400] loss: 0.018\n",
            "Accuracy of the network on the 10000 test images: 99.02 %\n",
            "[10,   100] loss: 0.016\n",
            "[10,   200] loss: 0.016\n",
            "[10,   300] loss: 0.012\n",
            "[10,   400] loss: 0.014\n",
            "Accuracy of the network on the 10000 test images: 98.84 %\n",
            "[11,   100] loss: 0.013\n",
            "[11,   200] loss: 0.010\n",
            "[11,   300] loss: 0.015\n",
            "[11,   400] loss: 0.014\n",
            "Accuracy of the network on the 10000 test images: 98.81 %\n",
            "[12,   100] loss: 0.013\n",
            "[12,   200] loss: 0.009\n",
            "[12,   300] loss: 0.012\n",
            "[12,   400] loss: 0.011\n",
            "Accuracy of the network on the 10000 test images: 99.01 %\n",
            "[13,   100] loss: 0.011\n",
            "[13,   200] loss: 0.007\n",
            "[13,   300] loss: 0.008\n",
            "[13,   400] loss: 0.009\n",
            "Accuracy of the network on the 10000 test images: 99.08 %\n",
            "[14,   100] loss: 0.009\n",
            "[14,   200] loss: 0.009\n",
            "[14,   300] loss: 0.013\n",
            "[14,   400] loss: 0.009\n",
            "Accuracy of the network on the 10000 test images: 99.21 %\n",
            "[15,   100] loss: 0.009\n",
            "[15,   200] loss: 0.006\n",
            "[15,   300] loss: 0.007\n",
            "[15,   400] loss: 0.006\n",
            "Accuracy of the network on the 10000 test images: 98.98 %\n",
            "[16,   100] loss: 0.005\n",
            "[16,   200] loss: 0.005\n",
            "[16,   300] loss: 0.009\n",
            "[16,   400] loss: 0.007\n",
            "Accuracy of the network on the 10000 test images: 98.97 %\n",
            "[17,   100] loss: 0.009\n",
            "[17,   200] loss: 0.006\n",
            "[17,   300] loss: 0.005\n",
            "[17,   400] loss: 0.005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "76yB8EnjL9lN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}